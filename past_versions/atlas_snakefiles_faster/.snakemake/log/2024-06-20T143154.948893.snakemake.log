Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job            count
-----------  -------
all                1
read_tissue        7
total              8

Select jobs to execute...
Execute 1 jobs...

[Thu Jun 20 14:31:55 2024]
localrule read_tissue:
    output: SRR17909505.txt
    jobid: 4
    reason: Missing output files: SRR17909505.txt; Code has changed since last execution
    wildcards: b=SRR17909505
    resources: tmpdir=/tmp

RuleException:
WorkflowError in file /charonfs/scratch/users/astar/gis/stufrancis/snakemake_tutorial/Snakefile, line 14:
Failed to open source file /charonfs/scratch/users/astar/gis/stufrancis/snakemake_tutorial/
        print(srr)
        
FileNotFoundError: [Errno 2] No such file or directory: '/charonfs/scratch/users/astar/gis/stufrancis/snakemake_tutorial/\n        print(srr)\n        '
[Thu Jun 20 14:31:55 2024]
Error in rule read_tissue:
    jobid: 4
    output: SRR17909505.txt

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-06-20T143154.948893.snakemake.log
WorkflowError:
At least one job did not complete successfully.
